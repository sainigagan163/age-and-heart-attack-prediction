{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a0e6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02b75955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION (ADJUST THESE) ---\n",
    "IMAGE_FOLDER = '/Users/gagan/Machine learning/Eye project/Fundus_CIMT_2903 Dataset'          # Folder containing the images\n",
    "DATA_FILE = 'data_info.csv' # Your metadata file (Check if it's .csv or .xlsx)\n",
    "IMG_SIZE = 128                   # Resize images to 128x128\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "306bca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_data():\n",
    "    print(f\"Reading data from {DATA_FILE}...\")\n",
    "    \n",
    "    # Load the CSV\n",
    "    df = pd.read_csv(DATA_FILE)\n",
    "    \n",
    "    # Print first few rows to confirm it works\n",
    "    print(f\"Found {len(df)} patients in the CSV.\")\n",
    "    \n",
    "    images = []\n",
    "    targets = [] \n",
    "\n",
    "    print(\"Loading images... (This might take a minute)\")\n",
    "    \n",
    "    # Loop through every patient in the CSV\n",
    "    count = 0\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        # 1. Get the Target (We use 'True_age' for Age Prediction)\n",
    "        # CHANGE THIS TO row['thickness'] IF YOU WANT TO PREDICT HEART RISK\n",
    "        patient_target = row['True_age'] \n",
    "        \n",
    "        # 2. Get Filenames for BOTH eyes\n",
    "        files_to_check = [ row['right_eye'], row['left_eye'] ]\n",
    "        \n",
    "        # 3. Load both images\n",
    "        for filename in files_to_check:\n",
    "            # Construct full path\n",
    "            img_path = os.path.join(IMAGE_FOLDER, filename)\n",
    "            \n",
    "            # Only load if the file actually exists\n",
    "            if os.path.exists(img_path):\n",
    "                img = cv2.imread(img_path)\n",
    "                \n",
    "                # --- Preprocessing ---\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                img = img[:, :, 1] # Keep Green Channel only (Best for vessels)\n",
    "                img = img / 255.0  # Normalize (0-1)\n",
    "                \n",
    "                # Reshape to (128, 128, 1) for the AI\n",
    "                img = np.expand_dims(img, axis=-1)\n",
    "                \n",
    "                images.append(img)\n",
    "                targets.append(patient_target)\n",
    "                count += 1\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    print(f\"Successfully loaded {count} images (Left + Right combined).\")\n",
    "    return np.array(images), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204bdac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \"\"\"\n",
    "    Standard CNN for Regression\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # Layer 1\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Layer 2\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Layer 3\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        Flatten(),\n",
    "        \n",
    "        # Dense Layers (Thinking layers)\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        \n",
    "        # Output: 1 single number (The Age)\n",
    "        Dense(1, activation='linear') \n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5342f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from data_info.csv...\n",
      "Found 2903 patients in the CSV.\n",
      "Loading images... (This might take a minute)\n",
      "Successfully loaded 5806 images (Left + Right combined).\n",
      "Starting training on 4644 images...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagan/Machine learning/Eye project/age-and-heart-attack-prediction/venv/lib/python3.13/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# --- MAIN EXECUTION ---\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 1. Load Data\n",
    "    X, y = load_and_process_data()\n",
    "    \n",
    "    if len(X) > 0:\n",
    "        # 2. Split Data (80% Train, 20% Test)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # 3. Build & Train\n",
    "        model = build_model()\n",
    "        \n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        \n",
    "        print(f\"Starting training on {len(X_train)} images...\")\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=30,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            validation_data=(X_test, y_test),\n",
    "            callbacks=[early_stop]\n",
    "        )\n",
    "        \n",
    "        # 4. Results\n",
    "        print(\"\\n--- Final Test Results ---\")\n",
    "        loss, mae = model.evaluate(X_test, y_test)\n",
    "        print(f\"Average Error: {mae:.2f} years\")\n",
    "        \n",
    "        # 5. Save\n",
    "        model.save('age_model.h5')\n",
    "        print(\"Model saved as age_model.h5\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Error: No images found. Please check your 'images' folder path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f70d5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
